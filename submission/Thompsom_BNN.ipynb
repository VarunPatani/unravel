{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b65ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU (CUDA) if available, otherwise CPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Model and Training Hyperparameters\n",
    "LEARNING_RATE = 0.001  # A small learning rate to ensure smooth and stable training\n",
    "EPOCHS = 120  # Increase epochs since we have early stopping\n",
    "BATCH_SIZE = 1024  # Batch size for training\n",
    "N_NEGATIVE_SAMPLES = (\n",
    "    15  # Number of negative samples to use for training per positive sample\n",
    ")\n",
    "EARLY_STOPPING_PATIENCE = 7  # Stop if validation loss doesn't improve for 7 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary data\n",
    "order_data = pd.read_csv(\"../Datasets/order_data_cleaned.csv\")\n",
    "customer_data = pd.read_csv(\"../Datasets/customer_data_cleaned.csv\")\n",
    "test_data = pd.read_csv(\"../Datasets/test_data_question.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e92e24",
   "metadata": {},
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9ab0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(categories=[[266, 400, 430, 801, 820, 822, 857, 949, 1070, 1161,\n",
       "                           1247, 1249, 1390, 1419, 1731, 1754, 1765, 1905, 1913,\n",
       "                           2154, 2156, 2249, 2315, 2513, 2517, 2734, 2786, 3302,\n",
       "                           3989, 4065, ...]],\n",
       "              handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(categories=[[266, 400, 430, 801, 820, 822, 857, 949, 1070, 1161,\n",
       "                           1247, 1249, 1390, 1419, 1731, 1754, 1765, 1905, 1913,\n",
       "                           2154, 2156, 2249, 2315, 2513, 2517, 2734, 2786, 3302,\n",
       "                           3989, 4065, ...]],\n",
       "              handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(categories=[[266, 400, 430, 801, 820, 822, 857, 949, 1070, 1161,\n",
       "                           1247, 1249, 1390, 1419, 1731, 1754, 1765, 1905, 1913,\n",
       "                           2154, 2156, 2249, 2315, 2513, 2517, 2734, 2786, 3302,\n",
       "                           3989, 4065, ...]],\n",
       "              handle_unknown='ignore', sparse_output=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract all item names from \"orders\" JSON string\n",
    "def extract_items(order_json_string):\n",
    "    try:\n",
    "        data = json.loads(order_json_string)\n",
    "        return [item[\"item_name\"] for item in data[\"orders\"][0][\"item_details\"]]\n",
    "    except (json.JSONDecodeError, IndexError, KeyError):\n",
    "        return []\n",
    "\n",
    "\n",
    "# This creates a column called \"item_list\" which contains all the item's in a list format included in that order\n",
    "order_data[\"item_list\"] = order_data[\"ORDERS\"].apply(extract_items)\n",
    "# this creates a set (to remove duplicates) to get all unique items in order_data\n",
    "all_items_in_orders = set(\n",
    "    [item for sublist in order_data[\"item_list\"] for item in sublist]\n",
    ")\n",
    "# this creates a set (to remove duplicates) to get all unique items in test_data\n",
    "all_items_in_test = (\n",
    "    set(test_data[\"item1\"].unique())\n",
    "    | set(test_data[\"item2\"].unique())\n",
    "    | set(test_data[\"item3\"].unique())\n",
    ")\n",
    "# this is basically a union list of all items from both sets created to get an idea of the overall number of unique items in the complete entire database\n",
    "ARM_VOCABULARY = sorted(list(all_items_in_orders | all_items_in_test))\n",
    "N_ARMS = len(ARM_VOCABULARY)\n",
    "\n",
    "# CONTEXT_FEATURES is a dictionary that maps feature names to their unique values\n",
    "# this basically stores all the unique different feature values for features that are included for our valuation/prediction\n",
    "CONTEXT_FEATURES = {\n",
    "    \"CUSTOMER_TYPE\": sorted(\n",
    "        customer_data[\"CUSTOMER_TYPE\"].astype(str).unique().tolist()\n",
    "    ),\n",
    "    \"STORE_NUMBER\": sorted(order_data[\"STORE_NUMBER\"].unique().tolist()),\n",
    "    \"ITEMS\": ARM_VOCABULARY,\n",
    "}\n",
    "# this creates a OneHotEncoder for the CUSTOMER_TYPE feature\n",
    "customer_type_encoder = OneHotEncoder(\n",
    "    categories=[CONTEXT_FEATURES[\"CUSTOMER_TYPE\"]],\n",
    "    handle_unknown=\"ignore\",\n",
    "    sparse_output=False,\n",
    ")\n",
    "# this creates a OneHotEncoder for the STORE_NUMBER feature\n",
    "store_number_encoder = OneHotEncoder(\n",
    "    categories=[CONTEXT_FEATURES[\"STORE_NUMBER\"]],\n",
    "    handle_unknown=\"ignore\",\n",
    "    sparse_output=False,\n",
    ")\n",
    "# the encoders are then fitted onto the respective feature sets which are converted into a 2D array of 1 column as OneHotEncoder expects input in 2D format\n",
    "customer_type_encoder.fit(np.array(CONTEXT_FEATURES[\"CUSTOMER_TYPE\"]).reshape(-1, 1))\n",
    "store_number_encoder.fit(np.array(CONTEXT_FEATURES[\"STORE_NUMBER\"]).reshape(-1, 1))\n",
    "\n",
    "# this creates a dictionary where each item is mapped to a unique index value (Dict so that O(1) access is possible)\n",
    "ARM_MAP = {item: i for i, item in enumerate(ARM_VOCABULARY)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2a11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of arms: 138, Number of context features: 182\n"
     ]
    }
   ],
   "source": [
    "def get_context_vector(customer_type, store_number, items_in_cart):\n",
    "    customer_vec = customer_type_encoder.transform(np.array([[customer_type]]))\n",
    "    store_vec = store_number_encoder.transform(np.array([[store_number]]))\n",
    "    items_vec = np.zeros((1, len(CONTEXT_FEATURES[\"ITEMS\"])))\n",
    "    for item in items_in_cart:\n",
    "        if item in ARM_MAP:\n",
    "            items_vec[0, ARM_MAP[item]] = 1\n",
    "    return np.concatenate(\n",
    "        [np.array([[1]]), customer_vec, store_vec, items_vec], axis=1\n",
    "    ).flatten()\n",
    "\n",
    "\n",
    "dummy_context = get_context_vector(\"Guest\", order_data[\"STORE_NUMBER\"].iloc[0], [])\n",
    "N_FEATURES = len(dummy_context)\n",
    "print(f\"Number of arms: {N_ARMS}, Number of context features: {N_FEATURES}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b02f5cd",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b44e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class to handle data efficiently for train_test_split purposes and training purposes.\n",
    "class BanditDataset(Dataset):\n",
    "    def __init__(self, contexts, arm_indices, rewards):\n",
    "        self.contexts = torch.FloatTensor(contexts)\n",
    "        self.arm_indices = torch.LongTensor(arm_indices)\n",
    "        self.rewards = torch.FloatTensor(rewards)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rewards)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.contexts[idx], self.arm_indices[idx], self.rewards[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7028d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35140/2942160848.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  order_data_merged[\"CUSTOMER_TYPE\"].fillna(\"Guest\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# creating a merged dataset on order and custome data on CUSTOMER_ID for creating the dataset\n",
    "order_data_merged = pd.merge(order_data, customer_data, on=\"CUSTOMER_ID\", how=\"left\")\n",
    "order_data_merged[\"CUSTOMER_TYPE\"].fillna(\"Guest\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56645c2",
   "metadata": {},
   "source": [
    "# Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842657be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1414410/1414410 [06:51<00:00, 3439.80it/s]\n",
      "/tmp/ipykernel_35140/2848279517.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647429097/work/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  self.contexts = torch.FloatTensor(contexts)\n"
     ]
    }
   ],
   "source": [
    "# Lists to store context, arm_index, reward gained from the training data\n",
    "contexts, arm_indices, rewards = [], [], []\n",
    "# Iterating through each row in the order_data_merged column\n",
    "for _, row in tqdm(order_data_merged.iterrows(), total=len(order_data_merged)):\n",
    "    # checking if number of items are more than 2 to be able to create context\n",
    "    items_in_order = row[\"item_list\"]\n",
    "    if len(items_in_order) < 2:\n",
    "        continue\n",
    "    # for each item in the order starting from the second item\n",
    "    for i in range(1, len(items_in_order)):\n",
    "        # choose the first 'i' items that is if i == 3 then choose the first 2 items as context\n",
    "        context_items = items_in_order[:i]\n",
    "        # chosen item is the i-th item to tell the model that this is the item to select for +ve reward\n",
    "        chosen_item = items_in_order[i]\n",
    "        # code to handle unknown cases so that it does not crash\n",
    "        if chosen_item not in ARM_MAP:\n",
    "            continue\n",
    "        # get context vector for the current row along with the context items\n",
    "        context_vector = get_context_vector(\n",
    "            row[\"CUSTOMER_TYPE\"], row[\"STORE_NUMBER\"], context_items\n",
    "        )\n",
    "        # append the necessary contexts ,arm_index and reward to the list for creation of training data\n",
    "        contexts.append(context_vector)\n",
    "        arm_indices.append(ARM_MAP[chosen_item])\n",
    "        rewards.append(1.0)\n",
    "        # create a list of possible negative samples that are not in the chosen items\n",
    "        possible_neg_items = [item for item in ARM_VOCABULARY if item != chosen_item]\n",
    "        # sample randomly '15' negative samples\n",
    "        neg_items = np.random.choice(\n",
    "            possible_neg_items, size=N_NEGATIVE_SAMPLES, replace=False\n",
    "        )\n",
    "        # for each negatuve item sampled append it lists to ensure that the model gets enough information on 'what not to suggest'.\n",
    "        for neg_item in neg_items:\n",
    "            contexts.append(context_vector)\n",
    "            arm_indices.append(ARM_MAP[neg_item])\n",
    "            rewards.append(0.0)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "(\n",
    "    contexts_train,\n",
    "    contexts_val,\n",
    "    arm_indices_train,\n",
    "    arm_indices_val,\n",
    "    rewards_train,\n",
    "    rewards_val,\n",
    ") = train_test_split(contexts, arm_indices, rewards, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create datasets for training and validation via custom created dataset\n",
    "train_dataset = BanditDataset(contexts_train, arm_indices_train, rewards_train)\n",
    "val_dataset = BanditDataset(contexts_val, arm_indices_val, rewards_val)\n",
    "\n",
    "# created data loaders to be used during training and evaluation phase\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71699a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the train and val loaders\n",
    "# with open(\"bandit_bnn_train_val_loaders.pkl\", \"wb\") as f:\n",
    "#     pickle.dump((train_loader, val_loader), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "462ad9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read train and val loaders\n",
    "# with open(\"bandit_bnn_train_val_loaders.pkl\", \"rb\") as f:\n",
    "#     train_loader, val_loader = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b59ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Class Balance Check ---\n",
      "0.0    21090660\n",
      "1.0     1406044\n",
      "Name: count, dtype: int64\n",
      "Positive-to-Negative Ratio: 1 to 15.0\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL HERE IS TO CHECK THE BALANCE OF THE CLASSES FOR POSITIVE AND NEGATIVE REWARDS\n",
    "\n",
    "# Convert the rewards list to a pandas Series for easy counting\n",
    "rewards_series = pd.Series(rewards)\n",
    "\n",
    "# Count the occurrences of each class (1.0 for positive, 0.0 for negative)\n",
    "class_counts = rewards_series.value_counts()\n",
    "\n",
    "print(\"\\n--- Class Balance Check ---\")\n",
    "print(class_counts)\n",
    "\n",
    "# Calculate and print the ratio\n",
    "if 0.0 in class_counts and 1.0 in class_counts:\n",
    "    ratio = class_counts[0.0] / class_counts[1.0]\n",
    "    print(f\"Positive-to-Negative Ratio: 1 to {ratio:.1f}\")\n",
    "print(\"---------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f1a7e7",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e65f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Bayesian Neural Network (with MC Dropout)\n",
    "class BanditBNN(nn.Module):\n",
    "    def __init__(self, n_features, n_arms, dropout_rate=0.5):\n",
    "        super(BanditBNN, self).__init__()\n",
    "        self.hidden1 = nn.Linear(n_features, 160)\n",
    "        self.dropout1 = nn.Dropout(p=dropout_rate)\n",
    "        self.hidden2 = nn.Linear(160, 140)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_rate)\n",
    "        self.output = nn.Linear(140, n_arms)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.dropout2(x)\n",
    "        return self.output(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish model name and path and initialize the optimzer and loss function\n",
    "MODEL_PATH = \"bandit_bnn_model_final.pth\"\n",
    "model = BanditBNN(N_FEATURES, N_ARMS).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# used BCEWithLogitsLoss as our problem is of a binary classification nature and this loss function is stable over using sigmoid() and BCELoss()\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374bd7f0",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c646258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Loop function\n",
    "def train_model():\n",
    "    print(\"Starting GPU training with validation and early stopping...\")\n",
    "    print(f\"LR : {LEARNING_RATE} \")\n",
    "    # Initialize variables for early stopping\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    save_epoch = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for context_batch, arm_idx_batch, reward_batch in tqdm(\n",
    "            train_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS} [Train]\"\n",
    "        ):\n",
    "            # Pass the inputs to the 'device' which is CUDA in in this case meaning \"GPU\".\n",
    "            context_batch, arm_idx_batch, reward_batch = (\n",
    "                context_batch.to(DEVICE),\n",
    "                arm_idx_batch.to(DEVICE),\n",
    "                reward_batch.to(DEVICE),\n",
    "            )\n",
    "            # clear previous accumulated gradients to prevent gradients from adding up across batches\n",
    "            optimizer.zero_grad()\n",
    "            # get the scores for all arms (returns a 138 size tenson of scores which are probabilities between 0-1)\n",
    "            all_arm_scores = model(context_batch)\n",
    "            # this code here gets the score for each chosen arm\n",
    "            # that is for each chosen arm index which we are storing at the start\n",
    "            # we gather the score at each index from the all_arm_scores matrix and we extract the score at that particular index\n",
    "            # this returns a list of score's which is usefull for calculating the loss for eaach batch.\n",
    "            chosen_arm_score = all_arm_scores.gather(\n",
    "                1, arm_idx_batch.unsqueeze(1)\n",
    "            ).squeeze()\n",
    "            # calculating the loss\n",
    "            loss = criterion(chosen_arm_score, reward_batch)\n",
    "            # perform backpropagation\n",
    "            loss.backward()\n",
    "            # updating the weights based on the loss\n",
    "            optimizer.step()\n",
    "            # appending the training loss\n",
    "            total_train_loss += loss.item()\n",
    "        # creating the average training loss for that batch\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()  # Set model to evaluation mode (disables dropout)\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for context_batch, arm_idx_batch, reward_batch in tqdm(\n",
    "                val_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS} [Val]\"\n",
    "            ):\n",
    "                context_batch, arm_idx_batch, reward_batch = (\n",
    "                    context_batch.to(DEVICE),\n",
    "                    arm_idx_batch.to(DEVICE),\n",
    "                    reward_batch.to(DEVICE),\n",
    "                )\n",
    "                all_arm_scores = model(context_batch)\n",
    "                chosen_arm_score = all_arm_scores.gather(\n",
    "                    1, arm_idx_batch.unsqueeze(1)\n",
    "                ).squeeze()\n",
    "                loss = criterion(chosen_arm_score, reward_batch)\n",
    "                total_val_loss += loss.item()\n",
    "        # creates the average validation loss for that batch\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1} finished. Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "        #  Early Stopping Logic on validation loss to avoid overfitting\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            # Save the models state (weights and biases)\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(f\"Validation loss improved. Saving best model to {MODEL_PATH}\")\n",
    "            save_epoch = epoch + 1  # Save the epoch when the model was saved to print\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(\n",
    "                f\"Validation loss did not improve. Patience: {patience_counter}/{EARLY_STOPPING_PATIENCE}\"\n",
    "            )\n",
    "\n",
    "        if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    print(f\"Training completed. Best model saved at epoch {save_epoch}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e30e200",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "193e2191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GPU training with validation and early stopping...\n",
      "LR : 0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/120 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19773/19773 [01:00<00:00, 328.03it/s]\n",
      "Epoch 1/120 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2197/2197 [00:06<00:00, 363.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished. Train Loss: 0.1549, Val Loss: 0.1477\n",
      "Validation loss improved. Saving best model to bandit_bnn_model_fourth_third.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/120 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19773/19773 [00:59<00:00, 331.44it/s]\n",
      "Epoch 2/120 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2197/2197 [00:06<00:00, 341.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 finished. Train Loss: 0.1513, Val Loss: 0.1474\n",
      "Validation loss improved. Saving best model to bandit_bnn_model_fourth_third.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/120 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19773/19773 [01:05<00:00, 303.09it/s]\n",
      "Epoch 3/120 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2197/2197 [00:06<00:00, 324.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished. Train Loss: 0.1508, Val Loss: 0.1470\n",
      "Validation loss improved. Saving best model to bandit_bnn_model_fourth_third.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/120 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19773/19773 [00:59<00:00, 333.95it/s]\n",
      "Epoch 4/120 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2197/2197 [00:06<00:00, 358.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 finished. Train Loss: 0.1505, Val Loss: 0.1472\n",
      "Validation loss did not improve. Patience: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/120 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19773/19773 [01:00<00:00, 324.27it/s]\n",
      "Epoch 5/120 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2197/2197 [00:06<00:00, 355.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 finished. Train Loss: 0.1504, Val Loss: 0.1472\n",
      "Validation loss did not improve. Patience: 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/120 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19773/19773 [01:02<00:00, 316.62it/s]\n",
      "Epoch 6/120 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2197/2197 [00:06<00:00, 350.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 finished. Train Loss: 0.1503, Val Loss: 0.1471\n",
      "Validation loss did not improve. Patience: 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/120 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19773/19773 [01:00<00:00, 327.46it/s]\n",
      "Epoch 7/120 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2197/2197 [00:06<00:00, 339.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 finished. Train Loss: 0.1504, Val Loss: 0.1471\n",
      "Validation loss did not improve. Patience: 4/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/120 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19773/19773 [00:59<00:00, 332.28it/s]\n",
      "Epoch 8/120 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2197/2197 [00:06<00:00, 364.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 finished. Train Loss: 0.1505, Val Loss: 0.1473\n",
      "Validation loss did not improve. Patience: 5/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/120 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19773/19773 [00:58<00:00, 335.20it/s]\n",
      "Epoch 9/120 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2197/2197 [00:06<00:00, 333.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 finished. Train Loss: 0.1506, Val Loss: 0.1472\n",
      "Validation loss did not improve. Patience: 6/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/120 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19773/19773 [00:59<00:00, 329.81it/s]\n",
      "Epoch 10/120 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2197/2197 [00:08<00:00, 262.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 finished. Train Loss: 0.1507, Val Loss: 0.1475\n",
      "Validation loss did not improve. Patience: 7/7\n",
      "Early stopping triggered.\n",
      "Training completed. Best model saved at epoch 3.\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7731c66",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0784b1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model from bandit_bnn_model_fourth_third.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35140/4192222711.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    }
   ],
   "source": [
    "# Saving and Loading Models\n",
    "def load_model():\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        print(f\"Loading best model from {MODEL_PATH}\")\n",
    "        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "    else:\n",
    "        print(\"Model file not found. Training from scratch.\")\n",
    "        train_model()\n",
    "\n",
    "\n",
    "load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ea0fa",
   "metadata": {},
   "source": [
    "# Recommendations function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f23703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating example recommendation ---\n",
      "Cart: ['Chicken Sub Combo', 'Ranch Dip - Regular', '10 pc Spicy Wings Combo']\n",
      "Top 3 Recommendations: ['8 pc Grilled Wings Combo', '2 pc Crispy Strips', '6 pc Grilled Wings Combo']\n"
     ]
    }
   ],
   "source": [
    "# Function that returns 'top_n' item recommendations based on customer context and items in cart along with the store number.\n",
    "def get_recommendations_gpu(customer_type, store_number, items_in_cart, top_n=3):\n",
    "    context_vector = get_context_vector(customer_type, store_number, items_in_cart)\n",
    "    context_tensor = torch.FloatTensor(context_vector).to(DEVICE)\n",
    "\n",
    "    # Enable dropout for Monte Carlo Dropout which resembles Thompson Sampling.\n",
    "    model.train()\n",
    "    with torch.no_grad():\n",
    "        scores = model(context_tensor)\n",
    "\n",
    "    # Get top_n recommendations\n",
    "    _, top_indices = torch.topk(scores, top_n)\n",
    "\n",
    "    # Get the item names for the top_n indices\n",
    "    return [ARM_VOCABULARY[i] for i in top_indices.cpu().numpy()]\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "print(\"\\n--- Generating example recommendation ---\")\n",
    "sample_row = test_data.iloc[0]\n",
    "cart = [sample_row[\"item1\"], sample_row[\"item2\"], sample_row[\"item3\"]]\n",
    "recs = get_recommendations_gpu(\n",
    "    sample_row[\"CUSTOMER_TYPE\"], sample_row[\"STORE_NUMBER\"], cart\n",
    ")\n",
    "print(f\"Cart: {cart}\")\n",
    "print(f\"Top 3 Recommendations: {recs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fcc27f",
   "metadata": {},
   "source": [
    "# Testing the model on a dataframe with 4 items in order\n",
    "NOTE: This data is taken from order_data_merged which was used to create the training and validation data so this is not a complete 'test' please refer to evaluate_BNN.ipynb last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "defef1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Recall@3 on a Holdout Set ---\n",
      "Created a holdout set with 93553 orders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Recall@3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93553/93553 [00:49<00:00, 1905.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Recall@3 Score on Holdout Set: 0.3705 (34663/93553 hits)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Final Evaluation on Holdout Set (Recall@3) ---\n",
    "print(\"\\n--- Calculating Recall@3 on a Holdout Set ---\")\n",
    "\n",
    "# Create a holdout test set from orders with exactly 4 items to mimic the competition test case\n",
    "holdout_df = order_data_merged[order_data_merged[\"item_list\"].apply(len) == 4].copy()\n",
    "print(f\"Created a holdout set with {len(holdout_df)} orders.\")\n",
    "\n",
    "hits = 0\n",
    "total = len(holdout_df)\n",
    "\n",
    "if total > 0:\n",
    "    for _, row in tqdm(holdout_df.iterrows(), total=total, desc=\"Evaluating Recall@3\"):\n",
    "        # The first 3 items are the context (the cart)\n",
    "        context_cart = row[\"item_list\"][:-1]\n",
    "        # The 4th item is the ground truth we want to predict\n",
    "        ground_truth_item = row[\"item_list\"][-1]\n",
    "\n",
    "        # Generate top 3 recommendations\n",
    "        recommendations = get_recommendations_gpu(\n",
    "            row[\"CUSTOMER_TYPE\"], row[\"STORE_NUMBER\"], context_cart\n",
    "        )\n",
    "\n",
    "        # Check if the ground truth is in our recommendations\n",
    "        if ground_truth_item in recommendations:\n",
    "            hits += 1\n",
    "\n",
    "    recall_at_3 = hits / total\n",
    "    print(\n",
    "        f\"\\nFinal Recall@3 Score on Holdout Set: {recall_at_3:.4f} ({hits}/{total} hits)\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No orders with exactly 4 items found to create a holdout set.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
